{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79746352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "374b8d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'country_col': 'country',\n",
    "    'year_col': 'year',\n",
    "    'crisis_col': 'crisisJST',\n",
    "    'gdp_col': 'rgdpmad',\n",
    "\n",
    "    'raw_cols': {\n",
    "        'cpi': 'cpi',\n",
    "        'money': 'money',\n",
    "        'housing': 'hpnom',\n",
    "        'credit': 'tloans',\n",
    "        'gdp': 'gdp',\n",
    "        'debtgdp': 'debtgdp',\n",
    "        'ltrate': 'ltrate',\n",
    "        'stir': 'stir',\n",
    "    },\n",
    "\n",
    "    \n",
    "    'pre_peak_window': 5,\n",
    "    'max_horizon': 15,\n",
    "    'drop_unrecovered': False,\n",
    "\n",
    "    \n",
    "    'exclude_shock_years': True,\n",
    "\n",
    "   \n",
    "    'feature_cols': [\n",
    "        'cpi_rate',\n",
    "        'money_rate',\n",
    "        'housing_rate',\n",
    "        'credit_rate',\n",
    "        'slope',\n",
    "        'global_credit_rate',\n",
    "        'global_slope',\n",
    "        'debtgdp_level',\n",
    "        'debtgdp_change',\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7945593c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _check_columns(df, cols, context=''):\n",
    "    missing = [c for c in cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(\n",
    "            f\"Missing columns {context}: {missing}\\n\"\n",
    "            f\"Available columns (first 60): {list(df.columns)[:60]}\" + (\" ...\" if len(df.columns) > 60 else \"\")\n",
    "        )\n",
    "\n",
    "\n",
    "def basic_panel_clean(df, cfg=CONFIG):\n",
    "    c = cfg['country_col']\n",
    "    y = cfg['year_col']\n",
    "    cr = cfg['crisis_col']\n",
    "    _check_columns(df, [c, y, cr], 'basic_panel_clean')\n",
    "\n",
    "    out = df.copy()\n",
    "    out[y] = pd.to_numeric(out[y], errors='coerce')\n",
    "    out = out.dropna(subset=[c, y]).copy()\n",
    "    out[y] = out[y].astype(int)\n",
    "\n",
    "    out[cr] = pd.to_numeric(out[cr], errors='coerce').fillna(0).astype(int)\n",
    "    out = out.sort_values([c, y]).reset_index(drop=True)\n",
    "\n",
    "    # Removing WWI and the Great Depression + WW2 1933â€“1945 \n",
    "    if cfg.get('exclude_shock_years', True):\n",
    "        out = out[\n",
    "            ((out[y] < 1914) | (out[y] > 1918)) &\n",
    "            ((out[y] < 1933) | (out[y] > 1945))\n",
    "        ].copy()\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def add_engineered_features(df, cfg=CONFIG):\n",
    "    c = cfg['country_col']\n",
    "    y = cfg['year_col']\n",
    "    raw = cfg['raw_cols']\n",
    "    _check_columns(df, [c, y] + list(raw.values()), 'add_engineered_features')\n",
    "\n",
    "    def _by_country(g):\n",
    "        g = g.sort_values(y).copy()\n",
    "\n",
    "        # (t - t-1)/(t-1): inflation, money growth, housing growth\n",
    "        g['cpi_rate'] = (g[raw['cpi']] - g[raw['cpi']].shift(1)) / g[raw['cpi']].shift(1)\n",
    "        g['money_rate'] = (g[raw['money']] - g[raw['money']].shift(1)) / g[raw['money']].shift(1)\n",
    "        g['housing_rate'] = (g[raw['housing']] - g[raw['housing']].shift(1)) / g[raw['housing']].shift(1)\n",
    "\n",
    "        g['credit_rate'] = (g[raw['credit']] / g[raw['gdp']]) - (g[raw['credit']].shift(1) / g[raw['gdp']].shift(1))\n",
    "\n",
    "        # Yield curve slope\n",
    "        g['slope'] = g[raw['ltrate']] - g[raw['stir']]\n",
    "\n",
    "        # Debt-to-GDP\n",
    "        g['debtgdp_level'] = g[raw['debtgdp']]\n",
    "        g['debtgdp_change'] = g[raw['debtgdp']] - g[raw['debtgdp']].shift(1)\n",
    "        return g\n",
    "\n",
    "    out = df.groupby(c, group_keys=False).apply(_by_country)\n",
    "\n",
    "    # global aggregates by year \n",
    "    out = out.groupby(y, group_keys=False).apply(\n",
    "        lambda x: x.assign(\n",
    "            global_credit_rate=x['credit_rate'].mean(skipna=True),\n",
    "            global_slope=x['slope'].mean(skipna=True)\n",
    "        )\n",
    "    )\n",
    "    return out\n",
    "\n",
    "\n",
    "def find_crisis_onsets(df, cfg=CONFIG):\n",
    "    c = cfg['country_col']\n",
    "    y = cfg['year_col']\n",
    "    cr = cfg['crisis_col']\n",
    "\n",
    "    out = df.sort_values([c, y]).copy()\n",
    "    out['_crisis_prev'] = out.groupby(c)[cr].shift(1).fillna(0).astype(int)\n",
    "    out['_onset'] = (out[cr] == 1) & (out['_crisis_prev'] == 0)\n",
    "    onsets = out.loc[out['_onset'], [c, y]].rename(columns={y: 'crisis_year'}).reset_index(drop=True)\n",
    "    return onsets\n",
    "\n",
    "\n",
    "def compute_recovery_time(country_df, crisis_year, gdp_col, year_col, pre_peak_window, max_horizon):\n",
    "    # Pre-crisis peak GDP\n",
    "    pre = country_df[(country_df[year_col] >= crisis_year - pre_peak_window) &\n",
    "                     (country_df[year_col] <= crisis_year - 1)]\n",
    "    if pre.empty or pre[gdp_col].dropna().empty:\n",
    "        return np.nan\n",
    "    pre_peak = float(pre[gdp_col].max())\n",
    "\n",
    "    post = country_df[(country_df[year_col] >= crisis_year + 1) &\n",
    "                      (country_df[year_col] <= crisis_year + max_horizon)][[year_col, gdp_col]].dropna()\n",
    "    if post.empty:\n",
    "        return np.nan\n",
    "\n",
    "    recovered_years = post.loc[post[gdp_col] >= pre_peak, year_col]\n",
    "    if recovered_years.empty:\n",
    "        return float(max_horizon)  # cap\n",
    "\n",
    "    return float(int(recovered_years.min()) - crisis_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec05ff87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(\n",
    "    df,\n",
    "    training_columns=None,\n",
    "    feature_means=None,\n",
    "    is_training=True,\n",
    "    verbose=False,\n",
    "    cfg=None\n",
    "):\n",
    "    if cfg is None:\n",
    "        cfg = CONFIG\n",
    "\n",
    "    feature_cols = cfg['feature_cols']\n",
    "\n",
    "    if is_training:\n",
    "\n",
    "        panel = basic_panel_clean(df, cfg)\n",
    "        panel = add_engineered_features(panel, cfg)\n",
    "\n",
    "        onsets = find_crisis_onsets(panel, cfg)\n",
    "        if verbose:\n",
    "            print('Crisis found:', len(onsets))\n",
    "\n",
    "        c = cfg['country_col']\n",
    "        ycol = cfg['year_col']\n",
    "        gdp_col = cfg['gdp_col']\n",
    "\n",
    "        _check_columns(panel, [gdp_col], 'GDP column for recovery definition')\n",
    "\n",
    "        episodes = []\n",
    "        for _, row in onsets.iterrows():\n",
    "            country = row[c]\n",
    "            t0 = int(row['crisis_year'])\n",
    "            cdf = panel[panel[c] == country]\n",
    "\n",
    "            rt = compute_recovery_time(\n",
    "                cdf,\n",
    "                crisis_year=t0,\n",
    "                gdp_col=gdp_col,\n",
    "                year_col=ycol,\n",
    "                pre_peak_window=int(cfg['pre_peak_window']),\n",
    "                max_horizon=int(cfg['max_horizon'])\n",
    "            )\n",
    "            episodes.append({c: country, 'crisis_year': t0, 'recovery_time': rt})\n",
    "\n",
    "        episodes = pd.DataFrame(episodes).dropna(subset=['recovery_time']).copy()\n",
    "        if cfg.get('drop_unrecovered', False):\n",
    "            episodes = episodes[\n",
    "                episodes['recovery_time'] < float(cfg['max_horizon'])\n",
    "            ].copy()\n",
    "\n",
    "        panel_at_t0 = panel.rename(columns={ycol: 'crisis_year'})[\n",
    "            [c, 'crisis_year'] + feature_cols\n",
    "        ].copy()\n",
    "        episodes = episodes.merge(panel_at_t0, on=[c, 'crisis_year'], how='left')\n",
    "\n",
    "        X = episodes[feature_cols].copy()\n",
    "        y = episodes['recovery_time'].copy()\n",
    "\n",
    "        continuous_cols = feature_cols[:]\n",
    "        means = X[continuous_cols].mean(numeric_only=True)\n",
    "        X[continuous_cols] = X[continuous_cols].fillna(means)\n",
    "\n",
    "        training_cols = X.columns.tolist()\n",
    "        feature_means = means.to_dict()\n",
    "\n",
    "        if verbose:\n",
    "            print('Episode dataset rows:', len(episodes))\n",
    "            print('Features:', training_cols)\n",
    "\n",
    "        return X, y, training_cols, continuous_cols, feature_means\n",
    "\n",
    "    else:\n",
    "        _check_columns(df, feature_cols, 'prediction Excel/template')\n",
    "        X = df[feature_cols].copy()\n",
    "\n",
    "        if feature_means is not None:\n",
    "            X = X.fillna(feature_means)\n",
    "        else:\n",
    "            X = X.fillna(X.mean(numeric_only=True))\n",
    "\n",
    "        if training_columns is not None:\n",
    "            X = X.reindex(columns=training_columns, fill_value=0)\n",
    "\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319aaae3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
